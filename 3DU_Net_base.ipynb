{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MONAI의 UNet 클래스\n",
        "- https://github.com/Project-MONAI/MONAI/blob/dev/docs/source/modules.md\n",
        "- 참고 코드 : https://github.com/czimaginginstitute/2024_czii_mlchallenge_notebooks/blob/main/3d_unet_monai/train.ipynb"
      ],
      "metadata": {
        "id": "IysV-RVPHj2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torchinfo\n",
        "import zarr, copick\n",
        "from tqdm import tqdm\n",
        "from monai.data import DataLoader, Dataset, CacheDataset, decollate_batch\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    EnsureChannelFirstd,\n",
        "    Orientationd,\n",
        "    AsDiscrete,\n",
        "    RandFlipd,\n",
        "    RandRotate90d,\n",
        "    NormalizeIntensityd,\n",
        "    RandCropByLabelClassesd,\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.losses import DiceLoss, FocalLoss, TverskyLoss\n",
        "from monai.metrics import DiceMetric, ConfusionMatrixMetric\n",
        "import mlflow                                                   # MLflow는 모델을 학습할 때 발생하는 각종 실험 데이터를 기록하는 기능\n",
        "import mlflow.pytorch"
      ],
      "metadata": {
        "id": "Nrh2_N1cL1YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = copick.from_file(copick_config_path)\n",
        "\n",
        "copick_user_name = \"copickUtils\"\n",
        "copick_segmentation_name = \"paintedPicks\"\n",
        "voxel_size = 10\n",
        "tomo_type = \"denoised\""
      ],
      "metadata": {
        "id": "QxBQWX5-LyZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tomogram types\n",
        "- raw\n",
        "- denoside(노이즈 제거)\n",
        "- filtered(필터링) : 가우시안, median 필터 등 사용\n",
        "- reconstructed : CT / MRI\n",
        "- segmented : 특정한 구조나 관심 영역을 분리한 형태, 각 픽셀에 특정 레이블이 할당\n",
        "- enhanced : 특정 부분의 대비 up, 엣지 강화\n",
        "- normalized : 픽셀 값 정규화, 스케일링\n",
        "- cropped(자르기)"
      ],
      "metadata": {
        "id": "e1vWVIjHMWDv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL7gSyF9HE7Y"
      },
      "outputs": [],
      "source": [
        "# 세그먼트 하는 과정 이해하기.\n",
        "from copick_utils.segmentation import segmentation_from_picks # 세그먼트(이미지를 분할하는 작업)를 진행\n",
        "import copick_utils.writers.write as write\n",
        "from collections import defaultdict # 기본값을 가지는 딕셔너리로, 키가 없을 때에도 기본값을 반환"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_masks = True # 마스크(이미지를 분할하는 과정에서 객체를 식별하는 데 사용되는 배열) 생성 옵션"
      ],
      "metadata": {
        "id": "3x2c-eIfHw6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 세그멘테이션(특정 객체를 분할하는 작업)을 수행하고 결과를 저장하는 과정\n",
        "if generate_masks:\n",
        "    target_objects = defaultdict(dict)                              # 각 객체에 대한 정보를 담은 딕셔너리 생성\n",
        "    for object in root.pickable_objects:\n",
        "        if object.is_particle:                                      # object.is_particle?\n",
        "            target_objects[object.name]['label'] = object.label     # 객체 label 저장\n",
        "            target_objects[object.name]['radius'] = object.radius   # 객체 반지름 정보 저장 => 왜?\n",
        "\n",
        "    for run in tqdm(root.runs):                     # tqdm을 사용해서 진행 상황을 보여줍니다.\n",
        "        tomo = run.get_voxel_spacing(10)            # Voxel은 3차원 이미지에서 픽셀, 10이라는 값으로 spacing\n",
        "        tomo = tomo.get_tomogram(tomo_type).numpy() # tomogram(3차원 이미지를 표현하는 데이터)을 넘파이 배열 형태로 변환\n",
        "        target = np.zeros(tomo.shape, dtype=np.uint8)\n",
        "        for pickable_object in root.pickable_objects:                                         # 선택 가능한 객체들(root.pickable_objects) 반복 처리\n",
        "            pick = run.get_picks(object_name=pickable_object.name, user_id=\"curation\")        # 사용자가 \"curation\"인 픽 데이터를 가져옴\n",
        "            if len(pick):\n",
        "                target = segmentation_from_picks.from_picks(pick[0],\n",
        "                                                            target,\n",
        "                                                            target_objects[pickable_object.name]['radius'] * 0.8, # why 0.8? -> resize 개념인건지? , 반경에 0.8을 곱하는 것은 세그멘테이션의 정확도 및 품질을 높이기 위한 조정 작업\n",
        "                                                            target_objects[pickable_object.name]['label']\n",
        "                                                            )\n",
        "        write.segmentation(run, target, copick_user_name, name=copick_segmentation_name)"
      ],
      "metadata": {
        "id": "OtrYzP6jH3M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dicts = []\n",
        "for run in tqdm(root.runs):\n",
        "    tomogram = run.get_voxel_spacing(voxel_size).get_tomogram(tomo_type).numpy()      # get_voxel_spacing(voxel_size)는 특정 voxel_size(3차원 픽셀 크기)를 적용하여 tomogram 데이터를 불러오는 메소드 #tomo_type은 tomogram의 종류나 형식\n",
        "    segmentation = run.get_segmentations(name=copick_segmentation_name, user_id=copick_user_name, voxel_size=voxel_size, is_multilabel=True)[0].numpy()\n",
        "    data_dicts.append({\"image\": tomogram, \"label\": segmentation})                     # tomogram과 segmentation 데이터를 하나의 딕셔너리로 묶어 data_dicts 리스트에 추가\n",
        "\n",
        "print(np.unique(data_dicts[0]['label']))"
      ],
      "metadata": {
        "id": "7g-30Y5cLHnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "pQuGT0qBPHpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_num_samples = 16                     # 랜덤 크롭(RandCrop) 과정에서 사용할 샘플의 수\n",
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "\n",
        "train_files, val_files = data_dicts[:5], data_dicts[5:7]\n",
        "print(f\"Number of training samples: {len(train_files)}\")\n",
        "print(f\"Number of validation samples: {len(val_files)}\")"
      ],
      "metadata": {
        "id": "sCB3It4RPHNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Non-random transforms (비랜덤 변환): 훈련 및 검증 데이터에 항상 적용될 변환들을 정의\n",
        "- Random transforms (랜덤 변환): 데이터 증강을 위해 훈련 중 무작위로 적용되는 변환들을 정의"
      ],
      "metadata": {
        "id": "Y5ZEa-trPae4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_random_transforms = Compose([\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),     # EnsureChannelFirstd: 이미지와 라벨의 채널이 첫 번째 축으로 생성\n",
        "    NormalizeIntensityd(keys=\"image\"),                                          # NormalizeIntensityd: 이미지의 강도를 정규화\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")                        # Orientationd: 이미지와 라벨의 방향을 RAS(좌표계)로 설정 / LPS(Left-Posterior-Superior)\n",
        "])\n",
        "\n",
        "random_transforms = Compose([\n",
        "    RandCropByLabelClassesd(                                                    # RandCropByLabelClassesd: 라벨을 기준으로 특정 클래스가 포함되도록 이미지와 라벨을 무작위로 크롭\n",
        "        keys=[\"image\", \"label\"],\n",
        "        label_key=\"label\",\n",
        "        spatial_size=[96, 96, 96],                                              # spatial_size는 크롭의 크기, num_samples는 각 이미지에서 자를 샘플의 수.\n",
        "        num_classes=8,\n",
        "        num_samples=my_num_samples\n",
        "    ),\n",
        "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),      # 특정 축 기준으로 90도 회전\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0)                # 뒤집기\n",
        "])"
      ],
      "metadata": {
        "id": "NV95siA4PeTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R (Right): 오른쪽 (Right) 방향\n",
        "- A (Anterior): 앞쪽 (Anterior) 방향\n",
        "- S (Superior): 위쪽 (Superior) 방향"
      ],
      "metadata": {
        "id": "0ajclEiWQ083"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터 설정"
      ],
      "metadata": {
        "id": "pKciuaFfQqq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = CacheDataset(data=train_files, transform=non_random_transforms, cache_rate=1.0)  # non_random_transforms를 적용한 후 데이터를 캐시, cache_rate에 따라 데이터 비율\n",
        "train_ds = Dataset(data=train_ds, transform=random_transforms)                              # 캐시된 데이터셋에 random_transforms를 적용하여 데이터 증강을 진행"
      ],
      "metadata": {
        "id": "Am2H2T5-QEHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터로드 설정"
      ],
      "metadata": {
        "id": "rk8ZoDkWQTb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True,                             # 데이터 무작위로 섞음\n",
        "    num_workers=4,                            # 프로세스의 수\n",
        "    pin_memory=torch.cuda.is_available()      #pin_memory는 GPU 메모리 전송 속도 up\n",
        ")"
      ],
      "metadata": {
        "id": "VVM9maTdQS5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증데이터 설정"
      ],
      "metadata": {
        "id": "drFimEZpQn7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = CacheDataset(data=val_files, transform=non_random_transforms, cache_rate=1.0)\n",
        "val_ds = Dataset(data=val_ds, transform=random_transforms)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=val_batch_size,\n",
        "    num_workers=4,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "ZYMC-Ny3QlWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설정"
      ],
      "metadata": {
        "id": "bZte-BchRTR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# Create UNet, DiceLoss and Adam optimizer\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=len(root.pickable_objects)+1,\n",
        "    channels=(48, 64, 80, 80),\n",
        "    strides=(2, 2, 1),\n",
        "    num_res_units=1,\n",
        ").to(device)\n",
        "\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "#loss_function = DiceLoss(include_background=True, to_onehot_y=True, softmax=True)  # softmax=True for multiclass\n",
        "loss_function = TverskyLoss(include_background=True, to_onehot_y=True, softmax=True)  # softmax=True for multiclass , # TverskyLoss는 이미지 분할(세그먼테이션) 작업에서 사용하는 손실 함수\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", ignore_empty=True)  # must use onehot for multiclass\n",
        "recall_metric = ConfusionMatrixMetric(include_background=False, metric_name=\"recall\", reduction=\"None\")"
      ],
      "metadata": {
        "id": "7k14daL5RRVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss 함수\n",
        "- TverskyLoss : FN(false negative), FP에 대해 가중치 조절, 불균형 클래스 문제에서 성능 up\n",
        "-  Dice Loss\n",
        "- 매개변수 :\n",
        "  - include_background=True : 배경 클래스를 포함할지 여부를 결정\n",
        "  - to_onehot_y=True : 라벨 데이터를 원-핫 인코딩(One-Hot Encoding)으로 변환\n",
        "  - softmax=True : 출력값에 소프트맥스를 적용"
      ],
      "metadata": {
        "id": "F0o7n-iaRnDw"
      }
    }
  ]
}