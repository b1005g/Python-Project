{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f95057-b983-413d-87f3-a7ba6313c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\b1005\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\b1005\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\b1005\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\b1005\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143c039e-524c-4fd5-b355-771844f5375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\b1005\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\b1005\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba7c0da-98a6-4a76-9c6b-83b01fe1221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: opencv-python\n",
      "Version: 4.10.0.84\n",
      "Summary: Wrapper package for OpenCV python bindings.\n",
      "Home-page: https://github.com/opencv/opencv-python\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\b1005\\anaconda3\\envs\\deeplearning\\lib\\site-packages\n",
      "Requires: numpy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d733ea-863f-447e-a516-e30d3e6bb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/JiahuiYu/generative_inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb592584-5ce3-4f99-a66f-c263821791d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67c1763e-6463-4daf-89d5-bb94259728f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 이미지 불러오기\n",
    "input_images = []\n",
    "gt_images = []\n",
    "input_folder = os.path.join(os.getcwd(), 'train_input')\n",
    "gt_folder = os.path.join(os.getcwd(), 'train_gt')\n",
    "\n",
    "# train_input 이미지와 train_gt 이미지 함께 불러오기\n",
    "for filename in os.listdir(input_folder):\n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    gt_path = os.path.join(gt_folder, filename)\n",
    "        \n",
    "    input_image = cv2.imread(input_path)\n",
    "    gt_image = cv2.imread(gt_path)\n",
    "        \n",
    "    # 이미지 BGR에서 RGB로 변환\n",
    "    input_rgb = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    input_images.append(input_rgb)\n",
    "    gt_images.append(gt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bff573-2d02-4b13-b22e-e6e61f960958",
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_images_telea = []\n",
    "repaired_images_ns = []\n",
    "\n",
    "# 각 이미지에 대해 마스크 생성 및 복원 작업 수행\n",
    "for input_img, gt_img in zip(input_images, gt_images):\n",
    "    # 두 이미지 간 차이를 계산하여 마스크 생성\n",
    "    difference = cv2.absdiff(input_image, gt_image)\n",
    "    # 차이의 임계값 적용하여 결손 영역만 마스크로 추출 (0~255 범위의 값 중 특정 임계값 설정)\n",
    "    _, mask = cv2.threshold(cv2.cvtColor(difference, cv2.COLOR_RGB2GRAY), 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Telea 알고리즘을 사용한 복원\n",
    "    inpaint_telea = cv2.inpaint(input_image, mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Navier-Stokes 알고리즘을 사용한 복원\n",
    "    inpaint_ns = cv2.inpaint(input_image, mask, 3, cv2.INPAINT_NS)\n",
    "    \n",
    "    # 복원된 이미지를 저장\n",
    "    repaired_images_telea.append(inpaint_telea)\n",
    "    repaired_images_ns.append(inpaint_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d94fc-6125-4211-aec5-d5f21e5ffe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (original, telea, ns) in enumerate(zip(input_images, repaired_images_telea, repaired_images_ns)):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 원본 이미지\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original)\n",
    "    plt.title('Original Input Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Telea 알고리즘을 사용한 복원 이미지\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(telea)\n",
    "    plt.title('Inpainting using Telea Algorithm')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Navier-Stokes 알고리즘을 사용한 복원 이미지\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(ns)\n",
    "    plt.title('Inpainting using Navier-Stokes Algorithm')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e84b64-1f54-484e-bc70-bbcfbaa61458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
